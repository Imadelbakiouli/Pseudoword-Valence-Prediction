{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Pseudoword Valence Using Cross-Linguistic Regression Models\n",
    "\n",
    "## Replicating and Extending *Valence Without Meaning* (Gatti et al., 2024)\n",
    "\n",
    "Imad-eddine El Bakiouli  \n",
    "BSc Cognitive Science & Artificial Intelligence  \n",
    "Tilburg University | 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcbFlt0uJpNc"
   },
   "source": [
    "This project extends the work of Gatti et al. by examining whether form–meaning mappings learned from a related language can capture the perceived valence of pseudowords. To investigate this, multiple linguistic resources were integrated and the original methodological pipeline was adapted accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "OQbS5Urfit8W",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "33483189-c53d-4a20-d953-efa6c4297720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'psycho-embeddings'...\n",
      "remote: Enumerating objects: 199, done.\u001b[K\n",
      "remote: Counting objects: 100% (199/199), done.\u001b[K\n",
      "remote: Compressing objects: 100% (138/138), done.\u001b[K\n",
      "remote: Total 199 (delta 105), reused 141 (delta 53), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (199/199), 67.91 KiB | 556.00 KiB/s, done.\n",
      "Resolving deltas: 100% (105/105), done.\n",
      "/content/psycho-embeddings/psycho-embeddings/psycho-embeddings/psycho-embeddings\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/MilaNLProc/psycho-embeddings.git\n",
    "%cd psycho-embeddings\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "ofb0L_c0AW0W"
   },
   "outputs": [],
   "source": [
    "# the solution to the assignment has been obtained using these packages.\n",
    "import nltk\n",
    "import torch\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import fasttext.util\n",
    "import fasttext as ft\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from psycho_embeddings import ContextualizedEmbedder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ra3phcRhKuuo"
   },
   "source": [
    "This project replicates the design proposed in *Valence without meaning* (Gatti et al., 2024). Linear regression models were trained using crowd-sourced Dutch valence ratings (Speed & Brysbaert, 2024) and applied to predict the valence of English pseudowords.\n",
    "\n",
    "To train the regression models, the dataset by Speed and Brysbaert (2024) was used, which contains crowd-sourced valence ratings for approximately 24,000 Dutch words. The metadata was usde to identify the relevant columns for analysis. The dataset is described in the paper *Ratings of valence, arousal, happiness, anger, fear, sadness, disgust, and surprise for 24,000 Dutch words* (Speed & Brysbaert, 2024).\n",
    "\n",
    "Two character-level models were implemented: a letter unigram model and a letter bigram model. Both models were trained exclusively on Dutch words.\n",
    "\n",
    "One important issue addressed in this project is that pseudowords created for English may correspond to valid Dutch words. To prevent this, the pseudoword list was filtered against a large store of Dutch words using the Dutch prevalence lexicon (OSF repository: https://osf.io/9zymw/). Any pseudoword for which a Dutch prevalence estimate was available was excluded, regardless of the prevalence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hrd4EhHlAcmi",
    "outputId": "ceb158a4-1f37-4e0c-bde1-ce60b1b6fd85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n",
      "First 5 lines of the dataset from Gatti:\n",
      "   X pseudoword     Value  predicted_valence  predictedL_valence  \\\n",
      "0  1     abhert  0.452501           7.414814            5.116167   \n",
      "1  2     abhict  0.434171           8.233714            5.059183   \n",
      "2  3     acleat  0.527803           5.552468            5.262971   \n",
      "3  4     acmure  0.604889           8.714640            5.120029   \n",
      "4  5      acoed  0.538990           7.340002            5.115652   \n",
      "\n",
      "   predictedL_Bi_valence  predicted_Dim_valence  predictedL_Dim_valence  \\\n",
      "0               6.444633               6.783771                6.630497   \n",
      "1               6.509936               7.366068                7.377534   \n",
      "2               5.245826               5.268643                5.396114   \n",
      "3               6.562896               7.680827                7.583230   \n",
      "4               5.309727               7.105662                7.024771   \n",
      "\n",
      "   predictedBi_Dim_valence  predictedBi_valence  LDist  Ortho_VAL  \\\n",
      "0                 7.414814             6.444633      2   4.655714   \n",
      "1                 8.233714             6.509936      2   3.093333   \n",
      "2                 5.552468             5.245826      1   4.240000   \n",
      "3                 7.809910             5.414532      2   5.885000   \n",
      "4                 7.340002             5.309727      1   5.680000   \n",
      "\n",
      "  Semant_Neigh     SDist  Semant_VAL  \n",
      "0     ordinary  0.558492        5.05  \n",
      "1     cardigan  0.622202        5.95  \n",
      "2     solarium  0.575150        6.10  \n",
      "3          bad  0.570299        3.24  \n",
      "4         girl  0.499035        7.15  \n",
      "First 5 lines of the data set from Speed and Brysbaert:\n",
      "   Word   Arousal   Valence ValenceCategory ValenceVsNeutral  Happiness  \\\n",
      "0  mama  2.812500  4.000000        positive         valenced   3.300000   \n",
      "1    ja  2.823529  3.894737        positive         valenced   3.818182   \n",
      "2  papa  2.562500  3.722222        positive         valenced   4.142857   \n",
      "3   nee  2.928571  2.350000        negative          neutral   1.000000   \n",
      "4  kaka  3.357143  2.050000        negative          neutral   1.090909   \n",
      "\n",
      "      Anger      Fear   Sadness   Disgust  ...  Length Nsyl  N_phonemes  \\\n",
      "0  1.000000  1.000000  1.100000  1.000000  ...       4    2           4   \n",
      "1  1.090909  1.181818  1.181818  1.000000  ...       2    1           2   \n",
      "2  1.142857  1.000000  1.000000  1.000000  ...       4    2           4   \n",
      "3  1.727273  1.363636  1.454545  1.363636  ...       3    1           2   \n",
      "4  1.454545  1.181818  1.000000  4.727273  ...       4    2           4   \n",
      "\n",
      "        PoS  OLD20       AoA      DLP_RT   DLP_Acc   DCP_RT DCP_Acc  \n",
      "0         N   1.55  2.044257  513.530256  1.000000   931.03    0.99  \n",
      "1  Function   1.00  2.250000  494.980294  1.000000  1014.77    1.00  \n",
      "2         N   1.65  2.336327  570.497647  1.000000   936.88    0.99  \n",
      "3  Function   1.00  2.555556  488.637879  0.902439  1088.01    1.00  \n",
      "4         N   1.80  2.611111  629.402647  0.850000  1605.49    0.53  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load pseudowords (Gatti et al.) and Dutch valence norms (Speed & Brysbaert, 2024) from Google Drive\n",
    "# Extract pseudoword column and inspect both datasets\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "\n",
    "gattifile = pd.read_csv(\"/content/drive/MyDrive/Gatti_pseudowords_1500.csv\")\n",
    "print(\"First 5 lines of the dataset from Gatti:\")\n",
    "print(gattifile.head())\n",
    "pseudowords = gattifile[\"pseudoword\"]\n",
    "\n",
    "xlsx_path = '/content/drive/MyDrive/SpeedBrysbaertEmotionNorms.xlsx'\n",
    "valence = pd.read_excel(xlsx_path)\n",
    "\n",
    "print(\"First 5 lines of the data set from Speed and Brysbaert:\")\n",
    "print(valence.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s8lmxZEyqr6z",
    "outputId": "388b283b-51c5-490a-84a0-4363dfda1c71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original pseudoword count: 1500\n",
      "Pseudowords removed: {'pimpen'}\n",
      "Remaining pseudoword count: 1499\n"
     ]
    }
   ],
   "source": [
    "# Filter pseudowords against the Dutch prevalence lexicon to remove items\n",
    "# that are valid Dutch words; retain only true pseudowords for analysis\n",
    "\n",
    "print(\"Original pseudoword count:\", len(gattifile))\n",
    "prev = pd.read_csv(\n",
    "    '/content/drive/MyDrive/prevalence_netherlands.csv',\n",
    "    sep='\\t'\n",
    ")\n",
    "\n",
    "valid_words = set(prev['word'].astype(str).str.lower())\n",
    "\n",
    "pws = gattifile['pseudoword'].astype(str)\n",
    "pws_low = pws.str.lower()\n",
    "\n",
    "mask_real = pws_low.isin(valid_words)\n",
    "removed = set(pws[mask_real])\n",
    "print(\"Pseudowords removed:\", removed)\n",
    "\n",
    "filtered_gatti = gattifile.loc[~mask_real].reset_index(drop=True)\n",
    "print(\"Remaining pseudoword count:\", len(filtered_gatti))\n",
    "\n",
    "pseudowords_list = filtered_gatti['pseudoword'].str.lower().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8zPZ2pbjGon2",
    "outputId": "c746ae46-0440-4917-92d4-a371174ce941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unigram vector for 'ampgrair':\n",
      "[2 0 0 0 0 0 1 0 1 0 0 0 1 0 0 1 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "\n",
      "Bigram vector for 'ampgrair':\n",
      "[0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Generate character unigram (1-gram) and bigram (2-gram) feature matrices\n",
    "# for Dutch training words and pseudowords\n",
    "\n",
    "dutch_words = valence[\"Word\"].str.lower().tolist()\n",
    "\n",
    "uni_vec = CountVectorizer(analyzer=\"char\", ngram_range=(1, 1))\n",
    "bi_vec  = CountVectorizer(analyzer=\"char\", ngram_range=(2, 2))\n",
    "\n",
    "X_dutch_uni = uni_vec.fit_transform(dutch_words)\n",
    "X_dutch_bi  = bi_vec.fit_transform(dutch_words)\n",
    "X_pseudo_uni = uni_vec.transform(pseudowords_list)\n",
    "X_pseudo_bi  = bi_vec.transform(pseudowords_list)\n",
    "\n",
    "ex = [\"ampgrair\"]\n",
    "uni_ex = uni_vec.transform(ex).toarray()[0]\n",
    "bi_ex  = bi_vec.transform(ex).toarray()[0]\n",
    "\n",
    "print(\"\\nUnigram vector for 'ampgrair':\")\n",
    "print(uni_ex)\n",
    "print(\"\\nBigram vector for 'ampgrair':\")\n",
    "print(bi_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-w9-ySEuPp1Y",
    "outputId": "b43df36e-7dae-43ec-a37f-d115b507b975"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram model R2 score: 0.0095\n",
      "Bigram model R2 score: 0.1160\n"
     ]
    }
   ],
   "source": [
    "# Train linear regression models on unigram and bigram features\n",
    "\n",
    "y = valence[\"Valence\"].values\n",
    "\n",
    "uni_model = LinearRegression().fit(X_dutch_uni, y)\n",
    "\n",
    "bi_model = LinearRegression().fit(X_dutch_bi, y)\n",
    "\n",
    "uni_r2 = uni_model.score(X_dutch_uni, y)\n",
    "bi_r2 = bi_model.score(X_dutch_bi, y)\n",
    "\n",
    "print(f\"Unigram model R2 score: {uni_r2:.4f}\")\n",
    "print(f\"Bigram model R2 score: {bi_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujTtO8VyG9Ap",
    "outputId": "3c878b06-55e2-4d6d-f785-5e300a687812"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted valence for pseudowords (unigram): [2.91964934 2.93271094 3.00193988 ... 2.83886063 2.84023961 2.79305788]\n",
      "Predicted valence for pseudowords (bigram) : [3.23914867 3.04290828 3.17845976 ... 2.86050361 3.00660316 3.05633199]\n",
      "\n",
      "Predicted valence for Dutch words (unigram): [2.97356517 3.04873071 2.99644161 ... 2.96466515 2.95004878 2.90939766]\n",
      "Predicted valence for Dutch words (bigram) : [3.07687701 2.86048787 3.14367623 ... 2.79148374 2.6557058  2.96608726]\n"
     ]
    }
   ],
   "source": [
    "# Generate valence predictions for pseudowords and Dutch words\n",
    "\n",
    "y_pseudo_pred_uni = uni_model.predict(X_pseudo_uni)\n",
    "y_pseudo_pred_bi  = bi_model.predict(X_pseudo_bi)\n",
    "\n",
    "y_train_pred_uni = uni_model.predict(X_dutch_uni)\n",
    "y_train_pred_bi  = bi_model.predict(X_dutch_bi)\n",
    "\n",
    "print(\"Predicted valence for pseudowords (unigram):\", y_pseudo_pred_uni)\n",
    "print(\"Predicted valence for pseudowords (bigram) :\", y_pseudo_pred_bi)\n",
    "print(\"\\nPredicted valence for Dutch words (unigram):\", y_train_pred_uni)\n",
    "print(\"Predicted valence for Dutch words (bigram) :\", y_train_pred_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9aDwbajtPxze",
    "outputId": "4cd8177f-9866-41a6-83fc-59c374cae0dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation (unigram) of Dutch words:    p = 0.090\n",
      "Spearman correlation (bigram)  of Dutch words:    p = 0.321\n",
      "Spearman correlation (unigram) of pseudowords:    p = 0.260\n",
      "Spearman correlation (bigram)  of pseudowords:    p = 0.101\n"
     ]
    }
   ],
   "source": [
    "# Compute Spearman correlations between predicted and observed valence\n",
    "\n",
    "r_uni_train, _ = spearmanr(y, y_train_pred_uni)\n",
    "r_bi_train,  _ = spearmanr(y, y_train_pred_bi)\n",
    "\n",
    "y_pseudo_true = filtered_gatti[\"Value\"].values\n",
    "\n",
    "y_pseudo_pred_uni = y_pseudo_pred_uni[:len(y_pseudo_true)]\n",
    "y_pseudo_pred_bi  = y_pseudo_pred_bi[:len(y_pseudo_true)]\n",
    "\n",
    "r_uni_pseudo, _ = spearmanr(y_pseudo_true, y_pseudo_pred_uni)\n",
    "r_bi_pseudo,  _ = spearmanr(y_pseudo_true, y_pseudo_pred_bi)\n",
    "\n",
    "print(f\"Spearman correlation (unigram) of Dutch words:    p = {r_uni_train:.3f}\")\n",
    "print(f\"Spearman correlation (bigram)  of Dutch words:    p = {r_bi_train:.3f}\")\n",
    "print(f\"Spearman correlation (unigram) of pseudowords:    p = {r_uni_pseudo:.3f}\")\n",
    "print(f\"Spearman correlation (bigram)  of pseudowords:    p = {r_bi_pseudo:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0P1rNg5QoDn"
   },
   "source": [
    "Following the approach of Gatti et al., the target strings (pseudowords and Dutch words from Speed and Brysbaert) were encoded using fastText embeddings. A multiple regression model was trained on the Dutch words and subsequently applied to the pseudowords introduced by Gatti et al.\n",
    "\n",
    "Model performance was evaluated by reporting the Spearman correlation coefficient between observed and predicted valence scores for both Dutch words and pseudowords.\n",
    "\n",
    "Pre-trained fastText embeddings for Dutch were used, obtained from the official fastText repository (https://fasttext.cc/docs/en/crawl-vectors.html).\n",
    "\n",
    "In addition, the properties and implications of the fastText embedding model were analysed to better understand its role in capturing form–meaning relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "pDeWgWUNAckd"
   },
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "ft = fasttext.load_model(\"/content/drive/MyDrive/cc.nl.300.bin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rUD0VUJeRhr3"
   },
   "source": [
    "### FastText Model Properties\n",
    "\n",
    "The pre-trained Dutch fastText embeddings have a dimensionality of 300.\n",
    "\n",
    "The model was trained using character n-grams ranging from length 3 to 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aW-XEksGR28U",
    "outputId": "33541db8-9950-40b4-c1a7-58248dcf07b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 values of 'speelplaats':\n",
      "[ 0.0253247  -0.00634261  0.02746305 -0.04024595  0.04888906  0.00660965\n",
      " -0.04152017 -0.01824508 -0.00645641  0.00093806  0.0708492  -0.03291791\n",
      "  0.00263817 -0.02825846 -0.02188046 -0.03188037 -0.01846142 -0.02203094\n",
      " -0.01883078 -0.00259199]\n",
      "\n",
      "First 20 values of 'danchunk':\n",
      "[-0.00592199  0.00097547  0.05925412  0.00053251 -0.00386978 -0.02089076\n",
      " -0.02829577  0.00972911 -0.02510111 -0.11454885 -0.02695064  0.01551034\n",
      "  0.02384409  0.01009528  0.04545438  0.00997385 -0.00474529  0.02524533\n",
      "  0.02430548 -0.02851078]\n"
     ]
    }
   ],
   "source": [
    "# Encode Dutch words and pseudowords using pre-trained fastText embeddings\n",
    "\n",
    "X_ft = np.vstack([ft.get_word_vector(w) for w in dutch_words])\n",
    "X_pw_ft = np.vstack([ft.get_word_vector(w) for w in pseudowords_list])\n",
    "\n",
    "real_word   = \"speelplaats\"\n",
    "pseudo_word = \"danchunk\"\n",
    "\n",
    "vec_real   = ft.get_word_vector(real_word)\n",
    "vec_pseudo = ft.get_word_vector(pseudo_word)\n",
    "\n",
    "print(f\"First 20 values of '{real_word}':\\n{vec_real[:20]}\\n\")\n",
    "print(f\"First 20 values of '{pseudo_word}':\\n{vec_pseudo[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ePBth7cSAJU",
    "outputId": "0b649dc5-630a-448a-8a6d-1780c70f2a20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText‐based regression R2 on Dutch valence: 0.5200443073017833\n"
     ]
    }
   ],
   "source": [
    "# Train regression model on word valence\n",
    "\n",
    "ft_reg = LinearRegression().fit(X_ft, y)\n",
    "\n",
    "print(\"FastText‐based regression R2 on Dutch valence:\", ft_reg.score(X_ft, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8aizBCXRxvNH",
    "outputId": "a4463f35-6435-4009-a460-796337a06f4d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted valence for pseudowords (FastText): [3.1155238 3.0766866 2.8852634 ... 3.0173347 2.9208107 2.9239726]\n",
      "Predicted valence for Dutch words (FastText): [4.3099604 2.865531  4.036543  ... 3.1800575 2.8078961 3.1230912]\n"
     ]
    }
   ],
   "source": [
    "# Apply the trained model to predict the valence of pseudowords from Gatti et al (2024).\n",
    "# Then apply the same model back onto the training set to see how well it predicts the valence of words in Speed and Brysbaert (2024).\n",
    "\n",
    "y_pw_pred_ft   = ft_reg.predict(X_pw_ft)\n",
    "y_train_pred_ft = ft_reg.predict(X_ft)\n",
    "\n",
    "print(\"Predicted valence for pseudowords (FastText):\", y_pw_pred_ft)\n",
    "print(\"Predicted valence for Dutch words (FastText):\", y_train_pred_ft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQoet822yvfQ",
    "outputId": "7ba422f4-fbaa-4f35-d747-33b1a2a4c050"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of Dutch words:      p = 0.724\n",
      "Spearman correlation of pseudowords :     p = 0.102\n"
     ]
    }
   ],
   "source": [
    "# compute the Spearman correlation coefficients between true valence and predicted valence for\n",
    "# - words from Speed and Brysbaert (2024)\n",
    "# - pseudowords from Gatti and colleagues (2024)\n",
    "\n",
    "r_dutch, p_dutch = spearmanr(y, y_train_pred_ft)\n",
    "r_pseudo, p_pseudo = spearmanr(y_pseudo_true, y_pw_pred_ft)\n",
    "\n",
    "print(f\"Spearman correlation of Dutch words:      p = {r_dutch:.3f}\")\n",
    "print(f\"Spearman correlation of pseudowords :     p = {r_pseudo:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wnqKJ5XOSTbM"
   },
   "source": [
    "### Transformer-Based Valence Prediction (RobBERT v2)\n",
    "\n",
    "In addition to character-based models, this project extends the analysis by incorporating contextual representations from a transformer-based model, specifically RobBERT v2 (https://huggingface.co/pdelobelle/robbert-v2-dutch-base).\n",
    "\n",
    "Following the same evaluation pipeline, Dutch words (Speed & Brysbaert, 2024) and pseudowords (Gatti et al.) were encoded using RobBERT embeddings extracted from layer 0, prior to the integration of positional information. For strings consisting of multiple tokens, token embeddings were averaged to obtain a single representation per string.\n",
    "\n",
    "A multiple regression model was trained on the valence ratings of Dutch words and subsequently applied to the pseudowords. Model performance was evaluated using the Spearman correlation coefficient between observed and predicted valence scores.\n",
    "\n",
    "Due to the computational cost of embedding thousands of strings, embeddings were generated incrementally and stored for reuse once verified. During development, smaller subsets of words were used to validate correctness before scaling to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "Ppi-Zcp6i9Rn",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "0f2ce90c-4f54-4e44-90d9-ecbf8c6c005f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/vocab.json\n",
      "loading file merges.txt from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/merges.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/tokenizer.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 40000\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--pdelobelle--robbert-v2-dutch-base/snapshots/271b8bf12b7e429434ce953efb432e8373e84453/model.safetensors\n",
      "Some weights of the model checkpoint at pdelobelle/robbert-v2-dutch-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pdelobelle/robbert-v2-dutch-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load and instantiate the right model\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"pdelobelle/robbert-v2-dutch-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqGVx_m-7c3Q",
    "outputId": "4b07c7f2-63f1-4e51-f4ab-4e08ce7311b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 values of 'miauwen':   [0.01574459858238697, -0.050622452050447464, -0.013598739169538021, 0.008594965562224388, -0.025512464344501495, 0.05335233733057976, 0.07680433243513107, -0.0515216588973999, 0.05702745541930199, 0.015662498772144318, -0.006799475289881229, -0.04346112906932831, 0.006691428832709789, 0.020613234490156174, -0.011536190286278725, 0.06474956125020981, 0.010083496570587158, -0.00346448365598917, 0.024953659623861313, -0.016500618308782578]\n",
      "First 20 values of 'lixtheless': [-0.018898235633969307, 0.06503724306821823, -0.06651163846254349, 0.04543512314558029, -0.002323267050087452, 0.011083191260695457, 0.00870988517999649, -0.031088024377822876, 0.008913702331483364, -0.02554977312684059, -0.009220123291015625, -0.011074005626142025, -0.07307430356740952, 0.05849800258874893, -0.004880142398178577, -0.03039686381816864, 0.02213442325592041, -0.01936710998415947, 0.07086442410945892, -0.031020576134324074]\n"
     ]
    }
   ],
   "source": [
    "# encode the words and pseudowords using RobBERT v2.\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Chunks a list into equal chunks containing n elements. Returns a list of lists.\"\"\"\n",
    "    chunked = []\n",
    "    for i in range(0, len(lst), n):\n",
    "        chunked.append(lst[i : i + n])\n",
    "    return chunked\n",
    "\n",
    "def embed_layer0(texts, batch_size=64):\n",
    "    embs = []\n",
    "    for batch in chunks(texts, batch_size):\n",
    "        enc = tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        with torch.no_grad():\n",
    "            lookup = model.roberta.embeddings.word_embeddings(enc[\"input_ids\"])\n",
    "        core = lookup[:, 1:-1, :]\n",
    "        embs.append(core.mean(dim=1))\n",
    "    return torch.cat(embs, dim=0)\n",
    "\n",
    "X_rob_dutch = embed_layer0(dutch_words,      batch_size=128)\n",
    "X_rob_pws   = embed_layer0(pseudowords_list, batch_size=128)\n",
    "\n",
    "example_vecs = embed_layer0([\"miauwen\", \"lixtheless\"], batch_size=2)\n",
    "print(\"First 20 values of 'miauwen':  \", example_vecs[0,:20].tolist())\n",
    "print(\"First 20 values of 'lixtheless':\", example_vecs[1,:20].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BFq3hHCDUPjL",
    "outputId": "2a3bae00-4a14-4d8e-e5e8-128791076f5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobBERT regression R² on Dutch valence: 0.29015233642237737\n"
     ]
    }
   ],
   "source": [
    "# train regression model on word valence estimates from Speed and Brysbaert (2024)\n",
    "\n",
    "rob_reg = LinearRegression().fit(X_rob_dutch, y)\n",
    "\n",
    "print(\"RobBERT regression R² on Dutch valence:\", rob_reg.score(X_rob_dutch, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "evaU9NAxUSoW",
    "outputId": "3e3c7108-9b1a-4df6-a0ad-930f23036464"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted valence for pseudowords: [2.9676025 2.8038704 2.6597714 ... 3.0554996 2.9347763 2.6780963]\n",
      "Predicted valence for Dutch words: [3.2607572 3.0649645 3.0775404 ... 2.7749772 2.9288225 3.0169504]\n"
     ]
    }
   ],
   "source": [
    "# apply the trained model to predict the valence of pseudowords from Gatti et al (2024).\n",
    "# Then apply the same model back onto the training set to see how well it predicts the valence of words in Speed and Brysbaert (2024).\n",
    "\n",
    "y_pw_pred_rob    = rob_reg.predict(X_rob_pws.numpy())\n",
    "y_train_pred_rob = rob_reg.predict(X_rob_dutch.numpy())\n",
    "\n",
    "print(\"Predicted valence for pseudowords:\", y_pw_pred_rob)\n",
    "print(\"Predicted valence for Dutch words:\", y_train_pred_rob)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVcuHS02UUPd",
    "outputId": "140740c1-0da0-428b-bcdc-e323329678e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation of Dutch words:    ρ = 0.515\n",
      "Spearman correlation of pseudowords:    ρ = 0.169\n"
     ]
    }
   ],
   "source": [
    "# compute the Spearman correlation coefficients between true valence and predicted valence for\n",
    "# - words from Speed and Brysbaert (2024)\n",
    "# - pseudowords from Gatti and colleagues (2024)\n",
    "# show the correlation coefficient\n",
    "\n",
    "r_rob_train, _ = spearmanr(y, y_train_pred_rob)\n",
    "r_rob_pws, _  = spearmanr(y_pseudo_true, y_pw_pred_rob)\n",
    "\n",
    "print(f\"Spearman correlation of Dutch words:    ρ = {r_rob_train:.3f}\")\n",
    "print(f\"Spearman correlation of pseudowords:    ρ = {r_rob_pws:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EONmoGe8CAyI"
   },
   "source": [
    "\n",
    "\n",
    "### Model Performance Comparison\n",
    "\n",
    "The performance of each featurization was analysed by comparing:\n",
    "- the performance of the same model between the training and test set,\n",
    "- the performance of different models on the training set,\n",
    "- the performance of different models on the test set.\n",
    "\n",
    "In the training set, the unigram model explains almost no variance (R² = 0.0095, ρ = 0.090), yet it generalizes best to pseudowords (ρ = 0.260). Bigrams capture more orthographic structure (R² = 0.1160, ρ = 0.321), but drop to ρ ≈ 0.101 on novel strings. FastText subword embeddings dominate in-sample (R² = 0.5200, ρ = 0.724), but collapse to ρ ≈ 0.102 out-of-sample. RobBERT layer-0 embeddings sit in between (R² = 0.2982, ρ = 0.515), with moderate generalization (ρ ≈ 0.169).\n",
    "\n",
    "Across models on training words, performance ranks as follows: \n",
    "1. fastText  \n",
    "2. RobBERT  \n",
    "3. bigrams  \n",
    "4. unigrams  \n",
    "\n",
    "On pseudowords, the ranking changes:\n",
    "1. unigrams  \n",
    "2. RobBERT  \n",
    "3. fastText & bigrams  \n",
    "\n",
    "These results indicate that while complex subword representations fit real-word valence extremely well, they overfit and struggle with novel letter strings, whereas simpler letter-frequency cues transfer more robustly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vv7P2zvnCBiX"
   },
   "source": [
    "### Cross-Linguistic Comparison with English Results\n",
    "\n",
    "The overall pattern observed in Dutch closely mirrors the English results reported by Gatti et al. (2023). In English, a linear model on single letters achieved only r = .11; adding bigrams raised this to r = .33, and a full fastText-enriched model reached r = .80.\n",
    "\n",
    "In Dutch, a similar progression is observed: very low correlation for unigrams (ρ = .09), a substantial increase for bigrams (ρ = .32), and the highest performance for fastText (ρ = .72).\n",
    "\n",
    "Thus, in both languages:\n",
    "1. Letter-only features capture minimal valence.\n",
    "2. Orthographic context (bigrams) yields a medium effect.\n",
    "3. Subword-informed embeddings provide the largest improvement.\n",
    "\n",
    "The main quantitative difference is that all Dutch correlations are slightly lower than their English counterparts — particularly fastText (ρ = .72 vs. r = .80) — suggesting somewhat weaker predictive regularity in Dutch valence norms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M-lvw2qVjNH"
   },
   "source": [
    "### Effect of N-gram Size in fastText\n",
    "\n",
    "FastText relies on subword n-grams, typically ranging from 3 to 6 characters. These enable strong in-sample performance by capturing meaningful orthographic structure. However, such representations do not generalize as effectively to pseudowords.\n",
    "\n",
    "Using shorter n-grams (e.g., 3–4 characters) could improve generalization to novel, made-up words by focusing on smaller orthographic units, although this might slightly reduce fit on real words.\n",
    "\n",
    "Conversely, extending the n-gram range (e.g., up to 8 characters) could further improve modeling of real Dutch words but may increase overfitting and worsen generalization to unseen strings.\n",
    "\n",
    "Given the observed drop in performance on pseudowords, slightly shorter n-grams could potentially yield a better balance between in-sample accuracy and generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_-zN3Vp2OBD"
   },
   "source": [
    "**4d.** Do you think that training the same models on uni-grams, bi-grams, fastText and transformer-based embeddings but using valence ratings for Finnish (a language which uses the same alphabet as English but is not a IndoEuropean language) words would yield a similar pattern of results? Justify your answer.\n",
    "\n",
    "(*4 points available, max 150 words*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "20T-4kCdVppE"
   },
   "source": [
    "### Expected Performance in Finnish\n",
    "\n",
    "Training the same models on Finnish valence ratings would likely yield a similar ranking pattern: fastText performing best, followed by transformer-based embeddings, then bigrams, and finally unigrams.\n",
    "\n",
    "However, the performance gaps between models may be larger in Finnish. Finnish words are typically longer and morphologically complex, which could benefit subword-aware models like fastText. At the same time, such complexity may further challenge simple letter-based models.\n",
    "\n",
    "Transformer models, such as RobBERT, may handle morphological variation more effectively due to contextual representation learning. Bigrams would likely struggle with highly inflected forms, and unigrams would remain the weakest representation.\n",
    "\n",
    "Overall, the ranking may remain stable, but differences between models would likely become more pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4ILTPziXptK"
   },
   "source": [
    "\n",
    "\n",
    "To further examine the orthographic similarity between pseudowords and existing Dutch vocabulary, the average Levenshtein Distance (aLD) was computed for each pseudoword relative to the 20 closest Dutch words at the smallest edit distance.\n",
    "\n",
    "The Dutch prevalence lexicon used earlier for filtering valid words was employed to retrieve the nearest lexical neighbors. For each pseudoword, distances to all valid Dutch words were computed, the 20 smallest distances were selected, and their average was calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OGks7N-JCjFu",
    "outputId": "57cb0040-952e-4760-f41b-d2a60f3d2dfb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nedukes: aLD = 2.900\n",
      "pewbin: aLD = 2.950\n",
      "vibcines: aLD = 3.550\n"
     ]
    }
   ],
   "source": [
    "# compute the average Levenshtein distance from each pseudoword to the words used to filter out pseudowords.\n",
    "# Show the aLD estimate for the pseudowords 'nedukes', 'pewbin', and 'vibcines'\n",
    "\n",
    "targets = ['nedukes', 'pewbin', 'vibcines']\n",
    "\n",
    "for pw in targets:\n",
    "    dists = [Levenshtein.distance(pw, w) for w in valid_words]\n",
    "    nearest20 = sorted(dists)[:20]\n",
    "    aLD = sum(nearest20) / 20\n",
    "    print(f\"{pw}: aLD = {aLD:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mpc4rmCHXhgZ",
    "outputId": "4aaa9d3f-b290-4ba6-b087-3312c7b0cb78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yuxwas   → 3 tokens: ['y', 'ux', 'was']\n",
      "skibfy   → 4 tokens: ['sk', 'ib', 'f', 'y']\n",
      "errords  → 3 tokens: ['er', 'ror', 'ds']\n"
     ]
    }
   ],
   "source": [
    "# record the number of tokens in which RobBERT divides each pseudoword\n",
    "# show the number of tokens for the pseudowords 'yuxwas', 'skibfy', and 'errords'\n",
    "\n",
    "pseudowords = [\"yuxwas\", \"skibfy\", \"errords\"]\n",
    "\n",
    "for pw in pseudowords:\n",
    "    token_ids = tokenizer.encode(pw, add_special_tokens=False)\n",
    "    tokens    = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "    print(f\"{pw:8s} → {len(tokens)} tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "dc2p7UXSCi-q"
   },
   "outputs": [],
   "source": [
    "# compute the residuals from all four regression models fitted before\n",
    "y_true = filtered_gatti[\"Value\"].values\n",
    "\n",
    "y_uni = y_pseudo_pred_uni[: len(y_true)]\n",
    "y_bi  = y_pseudo_pred_bi[: len(y_true)]\n",
    "y_ft  = y_pw_pred_ft[:   len(y_true)]\n",
    "y_rob = y_pw_pred_rob[:  len(y_true)]\n",
    "\n",
    "res_uni = y_true - y_uni\n",
    "res_bi  = y_true - y_bi\n",
    "res_ft  = y_true - y_ft\n",
    "res_rob = y_true - y_rob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkqJLI17C0Ml",
    "outputId": "5a73b8a0-859e-437a-b5ec-847e10f7204a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unigram  residual vs aLD → r = -0.117, p = 0.000\n",
      "Bigram   residual vs aLD → r = -0.109, p = 0.000\n",
      "fastText residual vs aLD → r = -0.094, p = 0.000\n",
      "RobERT   residual vs aLD → r = -0.017, p = 0.509\n",
      "RobERT residual vs tokens → r = 0.120, p = 0.000\n"
     ]
    }
   ],
   "source": [
    "# compute the Pearson's correlation between residuals and average LD for all models,\n",
    "# as well as the correlation between RobBERT v2 residuals and the number of tokens in which each pseudoword\n",
    "# is encoded by the RobBERT v2 model.\n",
    "# show all correlation coefficients\n",
    "\n",
    "aLD_list = []\n",
    "for pw in pseudowords_list:\n",
    "    dists = [Levenshtein.distance(pw, w) for w in valid_words]\n",
    "    nearest20 = sorted(dists)[:20]\n",
    "    aLD_list.append(sum(nearest20) / 20)\n",
    "aLD_array = np.array(aLD_list)\n",
    "\n",
    "token_counts_list = [\n",
    "    len(tokenizer.encode(pw, add_special_tokens=False))\n",
    "    for pw in pseudowords_list\n",
    "]\n",
    "token_counts = np.array(token_counts_list)\n",
    "\n",
    "\n",
    "for name, res in zip(\n",
    "    [\"Unigram\", \"Bigram\", \"fastText\", \"RobERT\"],\n",
    "    [res_uni, res_bi, res_ft, res_rob]\n",
    "):\n",
    "    r, p = pearsonr(res, aLD_array)\n",
    "    print(f\"{name:8s} residual vs aLD → r = {r:.3f}, p = {p:.3f}\")\n",
    "r_tok, p_tok = pearsonr(res_rob, token_counts)\n",
    "print(f\"RobERT residual vs tokens → r = {r_tok:.3f}, p = {p_tok:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvaOAjqxuHgm"
   },
   "source": [
    "## Relationship Between Model Errors, Edit Distance, and Tokenization\n",
    "\n",
    "The unigram, bigram, and fastText models each show a significant negative correlation between their residuals and average Levenshtein Distance (aLD) (r ≈ −.117, −.109, −.049; p < .001). This indicates that the further a pseudoword is from any real Dutch word, the more these models tend to overestimate its valence.\n",
    "\n",
    "RobBERT v2, however, shows no meaningful relationship between residuals and aLD (r = −.017; p = .51), suggesting that its prediction errors are not primarily driven by simple orthographic unfamiliarity.\n",
    "\n",
    "Within RobBERT, residuals correlate positively with the number of subword tokens (r = .120; p < .001). This suggests that pseudowords segmented into more subword units tend to have their valence underestimated."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
